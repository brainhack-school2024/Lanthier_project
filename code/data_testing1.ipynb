{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd825e2-dc9f-4b97-8af5-00952d965761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCode for generating the first data figure in the manuscript.\\n\\nAuthors: Julia Sprenger, Lyuba Zehl, Michael Denker\\n\\n\\nCopyright (c) 2017, Institute of Neuroscience and Medicine (INM-6),\\nForschungszentrum Juelich, Germany\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n* Redistributions of source code must retain the above copyright notice, this\\nlist of conditions and the following disclaimer.\\n* Redistributions in binary form must reproduce the above copyright notice,\\nthis list of conditions and the following disclaimer in the documentation\\nand/or other materials provided with the distribution.\\n* Neither the names of the copyright holders nor the names of the contributors\\nmay be used to endorse or promote products derived from this software without\\nspecific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Code for generating the first data figure in the manuscript.\n",
    "\n",
    "Authors: Julia Sprenger, Lyuba Zehl, Michael Denker\n",
    "\n",
    "\n",
    "Copyright (c) 2017, Institute of Neuroscience and Medicine (INM-6),\n",
    "Forschungszentrum Juelich, Germany\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this\n",
    "list of conditions and the following disclaimer.\n",
    "* Redistributions in binary form must reproduce the above copyright notice,\n",
    "this list of conditions and the following disclaimer in the documentation\n",
    "and/or other materials provided with the distribution.\n",
    "* Neither the names of the copyright holders nor the names of the contributors\n",
    "may be used to endorse or promote products derived from this software without\n",
    "specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae1c9ab1-11bc-471e-89ca-6e9aa2ebe3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import quantities as pq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import gridspec, ticker\n",
    "\n",
    "from reachgraspio import reachgraspio\n",
    "\n",
    "import odml.tools\n",
    "\n",
    "from neo import utils as neo_utils\n",
    "from neo_utils import load_segment\n",
    "import odml_utils\n",
    "\n",
    "# Imports from example_nix.py\n",
    "from neo import Block, Segment\n",
    "from neo.io import NixIO\n",
    "from neo.utils import cut_segment_by_epoch, add_epoch, get_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a971f30d-6fec-4e04-a0f8-975495813cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Define data and metadata directories\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def get_monkey_datafile(monkey):\n",
    "    if monkey == \"Lilou\":\n",
    "        return \"l101210-001\"  # ns2 (behavior) and ns5 present\n",
    "    elif monkey == \"Nikos2\":\n",
    "        return \"i140703-001\"  # ns2 and ns6 present\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Enter your dataset directory here\n",
    "datasetdir = \"../multielectrode_grasp/datasets_blackrock/\"\n",
    "\n",
    "trialtype_colors = {\n",
    "    'SGHF': 'MediumBlue', 'SGLF': 'Turquoise',\n",
    "    'PGHF': 'DarkGreen', 'PGLF': 'YellowGreen',\n",
    "    'LFSG': 'Orange', 'LFPG': 'Yellow',\n",
    "    'HFSG': 'DarkRed', 'HFPG': 'OrangeRed',\n",
    "    'SGSG': 'SteelBlue', 'PGPG': 'LimeGreen',\n",
    "    'NONE': 'k', 'PG': 'k', 'SG': 'k', 'LF': 'k', 'HF': 'k'}\n",
    "\n",
    "event_colors = {\n",
    "    'TS-ON': 'Gray',  # 'TS-OFF': 'Gray',\n",
    "    'WS-ON': 'Gray',  # 'WS-OFF': 'Gray',\n",
    "    'CUE-ON': 'Gray',\n",
    "    'CUE-OFF': 'Gray',\n",
    "    'GO-ON': 'Gray',  # 'GO-OFF': 'Gray',\n",
    "    #    'GO/RW-OFF': 'Gray',\n",
    "    'SR': 'Gray',  # 'SR-REP': 'Gray',\n",
    "    'RW-ON': 'Gray',  # 'RW-OFF': 'Gray',\n",
    "    'STOP': 'Gray'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d729b19-e1ec-48c5-aafe-7ecbdfd5a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Plot helper functions\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def force_aspect(ax, aspect=1):\n",
    "    ax.set_aspect(abs(\n",
    "        (ax.get_xlim()[1] - ax.get_xlim()[0]) /\n",
    "        (ax.get_ylim()[1] - ax.get_ylim()[0])) / aspect)\n",
    "\n",
    "\n",
    "def get_arraygrid(signals, chosen_el):\n",
    "    array_grid = np.ones((10, 10)) * 0.7\n",
    "\n",
    "    rejections = np.logical_or(signals.array_annotations['electrode_reject_HFC'],\n",
    "                               signals.array_annotations['electrode_reject_LFC'],\n",
    "                               signals.array_annotations['electrode_reject_IFC'])\n",
    "\n",
    "    for sig_idx in range(signals.shape[-1]):\n",
    "        connector_aligned_id = signals.array_annotations['connector_aligned_ids'][sig_idx]\n",
    "        x, y = int((connector_aligned_id -1)// 10), int((connector_aligned_id - 1) % 10)\n",
    "\n",
    "        if np.asarray(signals.array_annotations['channel_ids'][sig_idx], dtype=int) == chosen_el:\n",
    "            array_grid[x, y] = -0.7\n",
    "        elif rejections[sig_idx]:\n",
    "            array_grid[x, y] = -0.35\n",
    "        else:\n",
    "            array_grid[x, y] = 0\n",
    "\n",
    "    return np.ma.array(array_grid, mask=np.isnan(array_grid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0823d456-9e3a-44f9-b837-097bdc59271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Load data and metadata for a monkey\n",
    "# =============================================================================\n",
    "# CHANGE this parameter to load data of the different monkeys\n",
    "# monkey = 'Nikos2'\n",
    "monkey = 'Lilou'\n",
    "\n",
    "#chosen_el = {'Lilou': 71, 'Nikos2': 63}\n",
    "#chosen_units = {'Lilou': range(1, 5), 'Nikos2': range(1, 5)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f09aa21-63c8-439c-a273-51f7b862a691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Load data\n",
    "#\n",
    "# As a first step, we load the data file into memory as a Neo object.\n",
    "# =============================================================================\n",
    "\n",
    "# Specify the datafile\n",
    "datafile = get_monkey_datafile(monkey)\n",
    "\n",
    "# Specify the path to the recording session to load, eg,\n",
    "session_path = os.path.join(\"..\", \"multielectrode_grasp\",\"datasets_nix\", datafile + \".nix\")\n",
    "\n",
    "# Open the session for reading\n",
    "session = NixIO(session_path)\n",
    "\n",
    "# Channel ID to plot\n",
    "#target_channel_id = 62\n",
    "\n",
    "\n",
    "# Read the complete dataset in lazy mode generating all neo objects,\n",
    "# but not loading data into memory.  The lazy neo structure will contain objects\n",
    "# to capture all recorded data types (time series at 1000Hz (ns2) and 30kHz (ns6)\n",
    "# scaled to units of voltage, sorted spike trains, spike waveforms and events)\n",
    "# of the recording session and return it as a Neo Block. The\n",
    "# time shift of the ns2 signal (LFP) induced by the online filter is\n",
    "# automatically corrected for by a heuristic factor stored in the metadata\n",
    "# (correct_filter_shifts=True).\n",
    "\n",
    "block = session.read_block()\n",
    "\n",
    "# Validate there is only a single Segment present in the block\n",
    "assert len(block.segments) == 1\n",
    "\n",
    "# loading data content of all data objects during the first 300 seconds\n",
    "# data_segment = load_segment(block.segments[0], time_range=(None, 300*pq.s))\n",
    "##data_segment = block.segments[0]\n",
    "segment = block.segments[0]\n",
    "\n",
    "print(\"Session loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93a8e5d-b58e-4ade-a54f-284db9509813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get start and stop events of trials\n",
    "start_events = neo_utils.get_events(\n",
    "    segment,\n",
    "    **{\n",
    "    'name': 'TrialEvents',\n",
    "    'trial_event_labels': 'TS-ON',\n",
    "    'performance_in_trial': 255})\n",
    "stop_events = neo_utils.get_events(\n",
    "    segment,\n",
    "    **{\n",
    "    'name': 'TrialEvents',\n",
    "    'trial_event_labels': 'STOP',\n",
    "    'performance_in_trial': 255})\n",
    "\n",
    "# there should only be one event object for these conditions\n",
    "assert len(start_events) == 1\n",
    "assert len(stop_events) == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba640561-4621-4ad7-9cee-9beb2e6658f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nepochs_rest = neo_utils.get_epochs(segment, **{'label': 'rest'})\\nassert len(epochs_rest) == 1\\n\\nepochs_mvt = neo_utils.get_epochs(segment, **{'label': 'mvt'})\\nassert len(epochs_mvt) == 1\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert epochs between 10ms before TS to 50ms after RW corresponding to trails\n",
    "ep = neo_utils.add_epoch(\n",
    "    segment,\n",
    "    start_events[0],\n",
    "    stop_events[0],\n",
    "    pre=0 * pq.ms, #-250 * pq.ms,\n",
    "    post=0 * pq.ms, #500 * pq.ms,\n",
    "    trial_status='complete_trials')\n",
    "ep.array_annotate(trial_type=start_events[0].array_annotations['belongs_to_trialtype'],\n",
    "                  trial_performance=start_events[0].array_annotations['performance_in_trial'])\n",
    "\n",
    "\n",
    "epochs = neo_utils.get_epochs(segment, **{'trial_status': 'complete_trials'})\n",
    "assert len(epochs) == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1e5421-173e-4a58-ab09-4de22e32d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use most raw neuronal data if multiple versions are present\n",
    "max_sampling_rate = max([a.sampling_rate for a in segment.analogsignals])\n",
    "idx = 0\n",
    "while idx < len(segment.analogsignals):\n",
    "    signal = segment.analogsignals[idx]\n",
    "    if signal.annotations['neural_signal'] and signal.sampling_rate < max_sampling_rate:\n",
    "        segment.analogsignals.pop(idx)\n",
    "    else:\n",
    "        idx += 1\n",
    "\n",
    "# cut segments according to inserted 'complete_trials' epochs and reset trial times\n",
    "cut_segments = neo_utils.cut_segment_by_epoch(segment, epochs[0], reset_time=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d9fa5f0-123b-4b6b-8605-6cf4e244cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Feature and label extractions from data\n",
    "# =============================================================================\n",
    "\n",
    "# Determine a time windows to slide on the data\n",
    "window = 500 # ms (Choose here the size of the sliding window)\n",
    "window_len = window/1000*30000 # Number of points @ 30kHz\n",
    "window_time = (window * pq.ms).rescale(pq.s) # Window size in second\n",
    "\n",
    "# Passing through all segments with the time window, at each time frame, extract \n",
    "# the feature (1 value) and the label (rest or mvt). Write values in a csv file.\n",
    "\n",
    "electrode = 4 #comme figure 6\n",
    "\n",
    "# Feature 1 : mean over all electodes\n",
    "#feature = 'mean_over_electrodes'\n",
    "feature1 = 'mean_seg'\n",
    "feature2 = 'max-min'\n",
    "\n",
    "# Open a csv file in exclusive creating mode\n",
    "with open('features/'+feature1+'_'+feature2+'el_'+str(electrode)+'_11juin_v1.csv', mode='x') as fobj:\n",
    "    writer = csv.writer(fobj)\n",
    "    writer.writerow(['id_segment', 'label', feature1, feature2]) \n",
    "    for index, seg in enumerate(cut_segments) :\n",
    "        \n",
    "        # Calculate the number of resting frames in the segment\n",
    "        for events in seg.events:\n",
    "            if 'GO-ON' in events.labels :\n",
    "                start_arg = np.where(events.labels=='TS-ON')[0][0]\n",
    "                start_time = events.times[start_arg]\n",
    "                go_arg = np.where(events.labels=='GO-ON')[0][0]\n",
    "                go_time = events.times[go_arg]\n",
    "                stop_arg = np.where(events.labels=='STOP')[0][0]\n",
    "                stop_time = events.times[stop_arg]\n",
    "        frames_rest = round((go_time - start_time)/window_time).item()    \n",
    "\n",
    "        # Extract raw data of the segment\n",
    "        raw_data = [a for a in seg.analogsignals if a.annotations['neural_signal']]\n",
    "        assert len(raw_data) == 1\n",
    "        raw_data = raw_data[0]\n",
    "        raw_signal = raw_data[:, electrode]\n",
    "\n",
    "        # Slide the window throught the data of the segment to extract features and labels\n",
    "        for frame in range(int(np.floor(len(raw_signal)/window_len))) :\n",
    "            data_window = raw_signal[int(np.floor(frame*window_len)):int(np.floor((frame+1)*window_len))]\n",
    "            \n",
    "            # Extract feature for the window\n",
    "            mean_seg = np.mean(data_window)\n",
    "            max_min = max(data_window) - min(data_window)\n",
    "                \n",
    "            # Extract label\n",
    "            if frame<frames_rest:\n",
    "                label = 'rest'\n",
    "            else:\n",
    "                label = 'mvt'\n",
    "\n",
    "            # Write in csv file\n",
    "            writer.writerow([index, label, mean_seg, max_min]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde958e-8e5f-4407-b1f9-8f3ed0aa22ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
